# ===============================================
# Freya v2.0 - Requirements File
# ===============================================
# Auto-generated comprehensive requirements file
# with version pinning for reproducible builds.
#
# Installation:
#   pip install -r requirements.txt
#
# Date: 2024-12-04
# Python Version: >=3.11
# ===============================================

# ==================== Core Dependencies ====================

# Configuration & Environment
python-dotenv>=1.0.0,<2.0.0
pydantic>=2.5.0,<3.0.0
pydantic-settings>=2.1.0,<3.0.0

# Async & Concurrency (Built-in, but listed for clarity)
# asyncio>=3.4.3  # Note: asyncio is a built-in module in Python 3.11+

# ==================== Message Bus ====================

# Redis Client
redis>=5.0.0,<6.0.0
# Note: aioredis is now integrated into redis>=4.2.0
# Keeping for compatibility but may be redundant
aioredis>=2.0.1,<3.0.0  

# ==================== Web Framework (GUI Backend) ====================

# FastAPI & Server
fastapi>=0.109.0,<0.115.0
uvicorn[standard]>=0.27.0,<0.31.0
websockets>=12.0,<13.0
pyjwt>=2.8.0,<3.0.0

# ==================== LLM Integration ====================

# Ollama Python SDK
ollama>=0.1.0,<1.0.0

# ==================== Speech-to-Text ====================

# Whisper (GPU-accelerated)
faster-whisper>=0.10.0,<1.0.0

# ==================== Text-to-Speech ====================

# ElevenLabs API
elevenlabs>=0.2.0,<1.0.0

# ==================== Wake Word Detection ====================

# Porcupine
pvporcupine>=3.0.0,<4.0.0

# ==================== Memory & Vector Database ====================

# ChromaDB
chromadb>=0.4.22,<0.5.0

# ==================== Model Context Protocol (MCP) ====================

# MCP Python SDK
# Note: This is the official Anthropic MCP SDK
mcp>=1.0.0,<2.0.0

# HTTP Client for MCP servers
httpx>=0.25.0,<0.29.0

# Async file operations
aiofiles>=23.2.0,<24.0.0

# ==================== Vision ====================

# OpenCV
opencv-python>=4.9.0,<5.0.0

# YOLO (Ultralytics)
ultralytics>=8.1.0,<9.0.0

# ==================== Audio Processing ====================

# PyAudio (for audio capture)
pyaudio>=0.2.14,<0.3.0

# NumPy (for audio processing)
numpy>=1.26.0,<2.0.0

# SoundDevice (alternative audio library)
sounddevice>=0.4.6,<0.5.0

# ==================== Utilities ====================

# Logging
loguru>=0.7.2,<0.8.0

# JSON Logging
python-json-logger>=2.0.7,<3.0.0

# YAML parsing (for MCP servers config)
PyYAML>=6.0.1,<7.0.0

# ==================== Development Dependencies ====================
# Uncomment for development environment

# Testing
# pytest>=7.4.0,<8.0.0
# pytest-asyncio>=0.21.0,<0.22.0
# pytest-cov>=4.1.0,<5.0.0

# Code Quality
# black>=23.12.0,<24.0.0
# ruff>=0.1.9,<0.2.0
# mypy>=1.8.0,<2.0.0

# ==================== Version Conflicts & Notes ====================

# COMPATIBILITY NOTES:
#
# 1. Ollama vs MCP:
#    - No direct conflicts detected
#    - Both use httpx, which is compatible
#    - ollama>=0.1.0 uses httpx for API calls
#    - mcp>=1.0.0 uses httpx for server communication
#    - Shared httpx version: >=0.25.0,<0.29.0
#
# 2. Redis:
#    - redis>=5.0.0 includes async support
#    - aioredis>=2.0.1 is technically redundant but kept for compatibility
#    - Consider removing aioredis in future versions
#
# 3. FastAPI:
#    - fastapi>=0.109.0 requires pydantic>=2.5.0
#    - pydantic-settings>=2.1.0 is compatible
#    - uvicorn[standard] includes websockets
#
# 4. Audio Libraries:
#    - pyaudio requires portaudio19-dev system package
#    - Install on Debian/Ubuntu: sudo apt-get install portaudio19-dev
#    - sounddevice is an alternative that may be easier to install
#
# 5. Whisper:
#    - faster-whisper requires CUDA for GPU acceleration
#    - CPU fallback is available but slower
#    - Requires ffmpeg system package
#
# 6. Vision Libraries:
#    - ultralytics includes its own dependencies
#    - May have specific torch/torchvision requirements
#    - Check compatibility with CUDA version
#
# 7. ChromaDB:
#    - chromadb>=0.4.22 requires specific numpy version
#    - numpy>=1.26.0,<2.0.0 is compatible
#    - May require additional system packages
#
# SYSTEM DEPENDENCIES:
#
# Debian/Ubuntu:
#   sudo apt-get update && sudo apt-get install -y \
#     build-essential \
#     portaudio19-dev \
#     libsndfile1 \
#     ffmpeg \
#     git
#
# macOS (via Homebrew):
#   brew install portaudio ffmpeg
#
# CUDA/GPU Support:
#   - NVIDIA CUDA Toolkit 12.0+ required for GPU acceleration
#   - Ensure compatible NVIDIA drivers are installed
#   - Ollama requires GPU for optimal performance
#
# NODE.JS DEPENDENCIES (for MCP servers):
#   - Node.js 18+ required
#   - npm or npx required
#   - MCP servers are Node.js packages installed via npm
#   - See config/mcp_servers.yaml for specific MCP servers
#
# RECOMMENDED INSTALLATION ORDER:
#   1. Install system dependencies (apt-get, brew, etc.)
#   2. Install CUDA toolkit (if using GPU)
#   3. Install Python dependencies: pip install -r requirements.txt
#   4. Install Node.js and MCP servers: bash scripts/install_mcp_servers.sh
#   5. Pull Ollama models: ollama pull llama3.2:latest
#
# SECURITY CONSIDERATIONS:
#   - Review all package versions for known vulnerabilities
#   - Use pip-audit or safety to scan for security issues
#   - Keep dependencies updated regularly
#   - Consider using dependabot or renovate for automated updates
#
# PERFORMANCE OPTIMIZATION:
#   - Use binary wheels when available (--prefer-binary)
#   - Consider using conda for scientific packages
#   - Use virtual environment for isolation
#   - Consider using UV or PDM for faster dependency resolution
